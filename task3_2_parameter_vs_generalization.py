# -*- coding: utf-8 -*-
"""Task3_2_Parameter_vs_Generalization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e9irKiZjuSb3sOFCOEoY4mi5oSS-Av51
"""

pip install tensorflow==2.4

import tensorflow as tf
import numpy as np
import torch
import torchvision as tv
from torchvision import transforms, datasets
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
plt.style.use('seaborn-whitegrid')

trainingSet = datasets.MNIST('', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))
testingSet = datasets.MNIST('', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))
train = torch.utils.data.DataLoader(trainingSet, batch_size=50, shuffle=True)
test = torch.utils.data.DataLoader(testingSet, batch_size=50, shuffle=True)

def calcParams(inputModel):
    val = sum(params.numel() for params in inputModel.parameters() if params.requires_grad)
    return val

class Model1 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 4)
        self.fc2 = nn.Linear(4, 8)
        self.fc3 = nn.Linear(8, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val
    

class Model2 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 8)
        self.fc2 = nn.Linear(8, 16)
        self.fc3 = nn.Linear(16, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val
    

class Model3 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 15)
        self.fc2 = nn.Linear(15, 20)
        self.fc3 = nn.Linear(20, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val


class Model4 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 20)
        self.fc2 = nn.Linear(20, 25)
        self.fc3 = nn.Linear(25, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val
    

class Model5 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 32)
        self.fc2 = nn.Linear(32, 28)
        self.fc3 = nn.Linear(28, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val

class Model6 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 80)
        self.fc2 = nn.Linear(80, 32)
        self.fc3 = nn.Linear(32, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val
    

class Model7 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 250)
        self.fc2 = nn.Linear(250, 150)
        self.fc3 = nn.Linear(150, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val
    

class Model8 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 400)
        self.fc2 = nn.Linear(400, 250)
        self.fc3 = nn.Linear(250, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val


class Model9 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 550)
        self.fc2 = nn.Linear(550, 300)
        self.fc3 = nn.Linear(300, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val

class Model10 (nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 800)
        self.fc2 = nn.Linear(800, 400)
        self.fc3 = nn.Linear(400, 10)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = self.fc3(val)
        return val

model1 = Model1()
model2 = Model2()
model3 = Model3()
model4 = Model4()
model5 = Model5()
model6 = Model6()
model7 = Model7()
model8 = Model8()
model9 = Model9()
model10 = Model10()
costFunc = nn.CrossEntropyLoss()
model1Opt = optim.Adam(model1.parameters(), lr=0.001)
model2Opt = optim.Adam(model2.parameters(), lr=0.001)
model3Opt = optim.Adam(model3.parameters(), lr=0.001)
model4Opt = optim.Adam(model4.parameters(), lr=0.001)
model5Opt = optim.Adam(model5.parameters(), lr=0.001)
model6Opt = optim.Adam(model6.parameters(), lr=0.001)
model7Opt = optim.Adam(model7.parameters(), lr=0.001)
model8Opt = optim.Adam(model8.parameters(), lr=0.001)
model9Opt = optim.Adam(model9.parameters(), lr=0.001)
model10Opt = optim.Adam(model10.parameters(), lr=0.001)
model1Params = calcParams(model1)
model2Params = calcParams(model2)
model3Params = calcParams(model3)
model4Params = calcParams(model4)
model5Params = calcParams(model5)
model6Params = calcParams(model6)
model7Params = calcParams(model7)
model8Params = calcParams(model8)
model9Params = calcParams(model9)
model10Params = calcParams(model10)


print(model1Params)
print(model2Params)
print(model3Params)
print(model4Params)
print(model5Params)
print(model6Params)
print(model7Params)
print(model8Params)
print(model9Params)
print(model10Params)

# Train all models prior to testing and calc loss
EPOCHS = 50
counter = 0
counterList = []
for index in range(EPOCHS):
    counterList.append(counter)
    counter += 1
    # Print counter to show progress of training during computation
    print(counter)
    
    # Model 1
    for batch in train:
        inputImages, groundTruth = batch
        model1.zero_grad()
        output = model1(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model1Opt.step()

    # Model 2
    for batch in train:
        inputImages, groundTruth = batch
        model2.zero_grad()
        output = model2(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model2Opt.step()
        
    # Model 3
    for batch in train:
        inputImages, groundTruth = batch
        model3.zero_grad()
        output = model3(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model3Opt.step()
        
    # Model 4
    for batch in train:
        inputImages, groundTruth = batch
        model4.zero_grad()
        output = model4(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model4Opt.step()
        
    # Model 5
    for batch in train:
        inputImages, groundTruth = batch
        model5.zero_grad()
        output = model5(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model5Opt.step()
        
    # Model 6
    for batch in train:
        inputImages, groundTruth = batch
        model6.zero_grad()
        output = model6(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model6Opt.step()
        
    # Model 7
    for batch in train:
        inputImages, groundTruth = batch
        model7.zero_grad()
        output = model7(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model7Opt.step()
        
    # Model 8
    for batch in train:
        inputImages, groundTruth = batch
        model8.zero_grad()
        output = model8(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model8Opt.step()
        
    # Model 9
    for batch in train:
        inputImages, groundTruth = batch
        model9.zero_grad()
        output = model9(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model9Opt.step()
        
    # Model 10
    for batch in train:
        inputImages, groundTruth = batch
        model10.zero_grad()
        output = model10(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        cost.backward()
        model10Opt.step()

# Calculate loss and accuracy for every model for training set
# Model 1
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model1(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model1TrainCost = costTotal / costCounter
model1TrainAcc = round(correct/total, 3)

# Model 2
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model2(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model2TrainCost = costTotal / costCounter
model2TrainAcc = round(correct/total, 3)

# Model 3
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model3(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model3TrainCost = costTotal / costCounter
model3TrainAcc = round(correct/total, 3)

# Model 4
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model4(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model4TrainCost = costTotal / costCounter
model4TrainAcc = round(correct/total, 3)

# Model 5
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model5(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model5TrainCost = costTotal / costCounter
model5TrainAcc = round(correct/total, 3)

# Model 6
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model6(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model6TrainCost = costTotal / costCounter
model6TrainAcc = round(correct/total, 3)

# Model 7
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model7(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model7TrainCost = costTotal / costCounter
model7TrainAcc = round(correct/total, 3)

# Model 8
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model8(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model8TrainCost = costTotal / costCounter
model8TrainAcc = round(correct/total, 3)

# Model 9
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model9(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model9TrainCost = costTotal / costCounter
model9TrainAcc = round(correct/total, 3)

# Model 10
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in train:
        inputImages, groundTruth = batch
        output = model10(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model10TrainCost = costTotal / costCounter
model10TrainAcc = round(correct/total, 3)

# Calculate loss and accuracy for every model for testing set
# Model 1
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model1(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model1TestCost = costTotal / costCounter
model1TestAcc = round(correct/total, 3)

# Model 2
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model2(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model2TestCost = costTotal / costCounter
model2TestAcc = round(correct/total, 3)

# Model 3
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model3(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model3TestCost = costTotal / costCounter
model3TestAcc = round(correct/total, 3)

# Model 4
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model4(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model4TestCost = costTotal / costCounter
model4TestAcc = round(correct/total, 3)

# Model 5
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model5(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model5TestCost = costTotal / costCounter
model5TestAcc = round(correct/total, 3)

# Model 6
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model6(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model6TestCost = costTotal / costCounter
model6TestAcc = round(correct/total, 3)

# Model 7
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model7(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model7TestCost = costTotal / costCounter
model7TestAcc = round(correct/total, 3)

# Model 8
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model8(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model8TestCost = costTotal / costCounter
model8TestAcc = round(correct/total, 3)

# Model 9
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model9(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model9TestCost = costTotal / costCounter
model9TestAcc = round(correct/total, 3)

# Model 10
correct = 0
total = 0
costTotal = 0
costCounter = 0
with torch.no_grad():
    for batch in test:
        inputImages, groundTruth = batch
        output = model10(inputImages.view(-1,784))
        cost = costFunc(output, groundTruth)
        costTotal += cost
        costCounter += 1
        for i, outputTensor in enumerate(output):
            if torch.argmax(outputTensor) == groundTruth[i]:
                correct += 1
            total += 1
model10TestCost = costTotal / costCounter
model10TestAcc = round(correct/total, 3)

plt.plot(model1Params, model1TrainCost, 'b*')
plt.plot(model2Params, model2TrainCost, 'b*')
plt.plot(model3Params, model3TrainCost, 'b*')
plt.plot(model4Params, model4TrainCost, 'b*')
plt.plot(model5Params, model5TrainCost, 'b*')
plt.plot(model6Params, model6TrainCost, 'b*')
plt.plot(model7Params, model7TrainCost, 'b*')
plt.plot(model8Params, model8TrainCost, 'b*')
plt.plot(model9Params, model9TrainCost, 'b*')
plt.plot(model10Params, model10TrainCost, 'b*')

plt.plot(model1Params, model1TestCost, 'g^')
plt.plot(model2Params, model2TestCost, 'g^')
plt.plot(model3Params, model3TestCost, 'g^')
plt.plot(model4Params, model4TestCost, 'g^')
plt.plot(model5Params, model5TestCost, 'g^')
plt.plot(model6Params, model6TestCost, 'g^')
plt.plot(model7Params, model7TestCost, 'g^')
plt.plot(model8Params, model8TestCost, 'g^')
plt.plot(model9Params, model9TestCost, 'g^')
plt.plot(model10Params, model10TestCost, 'g^')
plt.title("Loss of Models")
plt.xlabel("Number of Parameters")
plt.ylabel("Cross Entropy Loss")
plt.annotate("Train", (model9Params, 0.37), color="blue", fontsize=14)
plt.annotate("Test", (model9Params, 0.34), color="green", fontsize=14)
plt.show()

plt.plot(model1Params, model1TrainAcc, 'b*')
plt.plot(model2Params, model2TrainAcc, 'b*')
plt.plot(model3Params, model3TrainAcc, 'b*')
plt.plot(model4Params, model4TrainAcc, 'b*')
plt.plot(model5Params, model5TrainAcc, 'b*')
plt.plot(model6Params, model6TrainAcc, 'b*')
plt.plot(model7Params, model7TrainAcc, 'b*')
plt.plot(model8Params, model8TrainAcc, 'b*')
plt.plot(model9Params, model9TrainAcc, 'b*')
plt.plot(model10Params, model10TrainAcc, 'b*')

plt.plot(model1Params, model1TestAcc, 'g^')
plt.plot(model2Params, model2TestAcc, 'g^')
plt.plot(model3Params, model3TestAcc, 'g^')
plt.plot(model4Params, model4TestAcc, 'g^')
plt.plot(model5Params, model5TestAcc, 'g^')
plt.plot(model6Params, model6TestAcc, 'g^')
plt.plot(model7Params, model7TestAcc, 'g^')
plt.plot(model8Params, model8TestAcc, 'g^')
plt.plot(model9Params, model9TestAcc, 'g^')
plt.plot(model10Params, model10TestAcc, 'g^')
plt.title("Accuracy of Models")
plt.xlabel("Number of Parameters")
plt.ylabel("Cross Entropy Loss")
plt.annotate("Train", (model9Params, 0.9), color="blue", fontsize=14)
plt.annotate("Test", (model9Params, 0.889), color="green", fontsize=14)
plt.show()