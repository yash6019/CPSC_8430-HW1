# -*- coding: utf-8 -*-
"""Task2_2_Observe_Gradient_Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lMoH1rdu3-UvjnDHiyMrLAQ1KJ8E68R3
"""

pip install tensorflow==2.4

# Commented out IPython magic to ensure Python compatibility.


import tensorflow as tf
import numpy as np
import torch
import torchvision as tv
from torchvision import transforms, datasets
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
# %matplotlib inline

simulatedInput = 20 * torch.rand((1000, 1)) - 10
groundTruth = np.cos(simulatedInput)

def calcParams(inputModel):
    val = sum(params.numel() for params in inputModel.parameters() if params.requires_grad)
    return val

class GradientNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(1, 5)
        self.fc2 = nn.Linear(5, 10)
        self.fc3 = nn.Linear(10, 5)
        self.fc4 = nn.Linear(5, 1)

    def forward(self, val):
        val = F.relu(self.fc1(val))
        val = F.relu(self.fc2(val))
        val = F.relu(self.fc3(val))
        val = self.fc4(val)
        return val

gradNet = GradientNN()
costFunc = nn.MSELoss()
opt = optim.Adam(gradNet.parameters(), lr=0.001)
EPOCHS = 2000

costList = []
gradNormList = []
counterList = []
counter = 1
for index in range(EPOCHS):
    counterList.append(counter)
    counter += 1
    gradNet.zero_grad()
    output = gradNet(simulatedInput)
    cost = costFunc(output, groundTruth)
    costList.append(cost)
    cost.backward()
    opt.step() 

    gradAll = 0.0
    for p in gradNet.parameters():
        grad = 0.0
        if p.grad is not None:
            grad = (p.grad.cpu().data.numpy() ** 2).sum()
        gradAll += grad
    gradNorm = gradAll ** 0.5
    gradNormList.append(gradNorm)

plt.plot(counterList, costList, 'b', label='Model')
plt.title("Learning Progression - cos(x)")
plt.xlabel("Number of EPOCHS")
plt.ylabel("Mean Squared Error")
plt.legend(loc="upper right")
plt.show()

plt.plot(counterList, gradNormList, 'b', label='Model')
plt.title("Gradient Norm during Training for cos(x)")
plt.xlabel("Number of EPOCHS")
plt.ylabel("Gradient Norm")
plt.legend(loc="upper right")
plt.show()